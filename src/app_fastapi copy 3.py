# -*- coding: utf-8 -*-
from fastapi import FastAPI, HTTPException, Body
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import PlainTextResponse
from pydantic import BaseModel
from typing import List, Optional, Set
from dotenv import load_dotenv
import os, glob
from datetime import datetime

# =========================
# bootstrap
# =========================
try:
    from .bootstrap import ensure_requirements_installed
except Exception:
    try:
        from bootstrap import ensure_requirements_installed
    except Exception:
        def ensure_requirements_installed(requirements_path: str = "requirements.txt",
                                          lock_path: str = ".requirements.sha256"):
            return False, "bootstrap module missing"

# =========================
# ë‚´ë¶€ ëª¨ë“ˆ
# =========================
try:
    from .pipeline_langchain import FarmLogPipeline, FarmLog
except Exception as e:
    raise RuntimeError(f"cannot import pipeline_langchain: {e}")

try:
    from .rag import build_or_load_vectorstore
except Exception as e:
    raise RuntimeError(f"cannot import rag: {e}")

# í†µí•© ë¶„ì„ê¸°
try:
    from .extract import analyse
except Exception as e:
    raise RuntimeError(f"cannot import extract.analyse: {e}")

# =========================
# ê²½ë¡œ/ìƒìˆ˜
# =========================
PROJ_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))

REQ_PATH   = os.getenv("REQUIREMENTS_PATH", os.path.join(PROJ_ROOT, "requirements.txt"))
REQ_LOCK   = os.getenv("REQUIREMENTS_LOCK", os.path.join(PROJ_ROOT, ".requirements.sha256"))
TEXT_DIR   = os.getenv("TEXT_DIR", os.path.join(PROJ_ROOT, "text"))
KB_DIR     = os.getenv("KB_DIR", os.path.join(PROJ_ROOT, "kb"))
CHROMA_DIR = os.getenv("CHROMA_DIR", os.path.join(PROJ_ROOT, "chroma"))
KEYWORDS_PATH = os.getenv("KEYWORDS_PATH", os.path.join(KB_DIR, "farming_keywords.txt"))

REJECT_MSG = (
    "í•´ë‹¹ ë‚´ìš©ì€ ë¶„ì„ê²°ê³¼ ì˜ë†ì¼ì§€ì™€ ê´€ë ¨ì—†ëŠ” ë‚´ìš©ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.\n"
    "ì˜ë†ì¼ì§€/ë†ì—… ê´€ë ¨ ë‚´ìš©ì„ ë§í•´ì£¼ì„¸ìš”."
)

# ê²Œì´íŠ¸ê°€ ë¹„ì–´ ìˆê±°ë‚˜ ë„ˆë¬´ ëŠìŠ¨í•  ë•Œë¥¼ ëŒ€ë¹„í•œ ê¸°ë³¸ í‚¤ì›Œë“œ(í´ë°±)
_DEFAULT_FARM_KEYWORDS: Set[str] = {
    "ì˜ë†","ë†ì—…","ë†ì‚¬","ì‘ëª©","ì‘ë¬¼","ì¬ë°°","í¬ì¥","í•˜ìš°ìŠ¤","ê³¼ì›","ë…¼","ë°­",
    "ê´€ìˆ˜","çŒæ°´","ì‹œë¹„","ë¹„ë£Œ","ì—½ë©´ì‹œë¹„","ë°©ì œ","ì œì´ˆ","íŒŒì¢…","ì •ì‹","ìˆ˜í™•","ì ê³¼","ì „ì •","ë©€ì¹­",
    "ë†ì•½","REI","PHI","ë³‘í•´","í•´ì¶©","ì§„ë”§ë¬¼","ì´ì±„","íƒ„ì €","ì—­ë³‘","í°ê°€ë£¨","ë…¸ê· ","ì‘ì• ","ê°€ë£¨ì´",
    "ë°°ì¶”","ê³ ì¶”","ì‚¬ê³¼","í† ë§ˆí† ","ê°ì","ìƒì¶”","ë”¸ê¸°","íŒŒí”„ë¦¬ì¹´","ì˜¤ì´","ì°¸ì™¸","í¬ë„","ë³µìˆ­ì•„",
}

# =========================
# FastAPI
# =========================
app = FastAPI(title="FarmLog STTâ†’RAG Baseline")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =========================
# Pydantic models
# =========================
class SummariseRequest(BaseModel):
    stt_text: str
    date_hint: Optional[str] = None
    crop_hint: Optional[str] = None
    location_hint: Optional[str] = None
    search_queries: Optional[List[str]] = None

class IngestRequest(BaseModel):
    kb_dir: Optional[str] = None

class SummariseFileRequest(BaseModel):
    filename: Optional[str] = None
    date_hint: Optional[str] = None
    crop_hint: Optional[str] = None
    location_hint: Optional[str] = None
    search_queries: Optional[List[str]] = None

class TextInfo(BaseModel):
    name: str
    size: int
    mtime: str  # ISO8601

class SummarisePathJSON(BaseModel):
    path: str
    date_hint: Optional[str] = None
    crop_hint: Optional[str] = None
    location_hint: Optional[str] = None
    search_queries: Optional[List[str]] = None

class SummariseAutoRequest(BaseModel):
    path: Optional[str] = None         # text/xxx.txt
    stt_text: Optional[str] = None     # íŒŒì¼ ëŒ€ì‹  ì§ì ‘ í…ìŠ¤íŠ¸
    date_hint: Optional[str] = None    # ìˆìœ¼ë©´ analyse ê²°ê³¼ë³´ë‹¤ ìš°ì„  ì ìš©

# =========================
# ì „ì—­ ìƒíƒœ
# =========================
_pipeline: Optional[FarmLogPipeline] = None

# =========================
# ìœ í‹¸: text/ íŒŒì¼
# =========================
def _list_text_files() -> List[TextInfo]:
    os.makedirs(TEXT_DIR, exist_ok=True)
    files = sorted(glob.glob(os.path.join(TEXT_DIR, "*.txt")))
    out: List[TextInfo] = []
    for fp in files:
        st = os.stat(fp)
        out.append(TextInfo(
            name=os.path.basename(fp),
            size=st.st_size,
            mtime=datetime.fromtimestamp(st.st_mtime).isoformat(timespec="seconds"),
        ))
    return out

def _read_text_file_safe(filename: str) -> str:
    if not filename or any(ch in filename for ch in ("..", "/", "\\")):
        raise HTTPException(status_code=400, detail="filename must be a base name under TEXT_DIR")
    path = os.path.join(TEXT_DIR, filename)
    if not os.path.exists(path):
        raise HTTPException(status_code=404, detail=f"file not found: {filename}")
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

def _normalise_to_basename(path: str) -> str:
    base = os.path.basename((path or "").strip())
    if not base or any(ch in base for ch in ("..", "/", "\\")):
        raise HTTPException(status_code=400, detail="invalid path")
    return base

# =========================
# í‚¤ì›Œë“œ ë¡œë”© (farming_keywords.txt)
# =========================
def _load_farm_keywords(path: str) -> Set[str]:
    kws: Set[str] = set()
    try:
        if not os.path.exists(path):
            return set()
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith("#"):
                    continue
                if "#" in line:
                    line = line.split("#", 1)[0].strip()
                parts = []
                if "," in line:
                    for p in line.split(","):
                        parts.extend(p.strip().split())
                else:
                    parts = line.split()
                for p in parts:
                    p = p.strip()
                    if p:
                        kws.add(p)
    except Exception:
        return set()
    return kws

# =========================
# ìŠ¤íƒ€íŠ¸ì—…
# =========================
@app.on_event("startup")
def _startup():
    load_dotenv()

    installed, msg = ensure_requirements_installed(requirements_path=REQ_PATH, lock_path=REQ_LOCK)
    app.state.requirements_status = {"installed_or_ok": installed, "message": msg}

    try:
        vs, backend = build_or_load_vectorstore(
            kb_dir=KB_DIR,
            persist_dir=CHROMA_DIR,
            force_vectorstore=os.getenv("FORCE_VECTORSTORE"),
        )
        app.state.vector_backend = backend
    except Exception as e:
        app.state.vector_backend = f"indexing-error: {e}"

    # í‚¤ì›Œë“œ ìºì‹œ (ë¹ˆ ê²°ê³¼/ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í‚¤ì›Œë“œ í´ë°±)
    try:
        kws = _load_farm_keywords(KEYWORDS_PATH)
        if not kws:
            kws = set(_DEFAULT_FARM_KEYWORDS)
        app.state.farm_keywords = kws
    except Exception:
        app.state.farm_keywords = set(_DEFAULT_FARM_KEYWORDS)

# =========================
# í—¬ìŠ¤/ë¦¬ìŠ¤íŠ¸
# =========================
@app.get("/healthz")
def healthz():
    return {
        "status": "ok",
        "requirements": getattr(app.state, "requirements_status", None),
        "vector_backend": getattr(app.state, "vector_backend", None),
        "keywords_count": len(getattr(app.state, "farm_keywords", set())),
        "keywords_path": KEYWORDS_PATH,
        "gate_min_hits": int(os.getenv("FARM_GATE_MIN_HITS", "2")),
    }

@app.get("/texts", response_model=List[TextInfo])
def list_texts():
    return _list_text_files()

# =========================
# ê³µí†µ ì‹¤í–‰ í—¬í¼ (ê²Œì´íŠ¸ ê°•í™”)
# =========================
def _run_with_analysis(
    stt_text: str,
    date_hint: Optional[str] = None,
    crop_hint: Optional[str] = None,
    location_hint: Optional[str] = None,
    search_queries: Optional[List[str]] = None,
) -> FarmLog:
    # 1) í†µí•© ë¶„ì„ (ê²Œì´íŠ¸ + íŒíŠ¸ ì¶”ì¶œ)
    domain_kws: Set[str] = getattr(app.state, "farm_keywords", set())
    if not domain_kws:
        # í˜¹ì‹œ ëª¨ë¥¼ ì˜ˆì™¸ ìƒí™©(í‚¤ì›Œë“œ ë¯¸ë¡œë“œ) í´ë°±
        domain_kws = set(_DEFAULT_FARM_KEYWORDS)
        app.state.farm_keywords = domain_kws

    res = analyse(stt_text, domain_kws, default_date=date_hint)

    # ğŸ”’ ê²Œì´íŠ¸ ê°•í™”: MIN_HITS(ê¸°ë³¸ 2) ê·œì¹™ + crop/location ëŒ€ì•ˆ
    try:
        min_hits = int(os.getenv("FARM_GATE_MIN_HITS", "2"))
    except Exception:
        min_hits = 2

    domain_hits = int(res.get("domain_hits") or 0)
    crop_auto = res.get("crop_hint")
    loc_auto  = res.get("location_hint")

    # ì‚¬ìš©ìê°€ ëª…ì‹œí•œ íŒíŠ¸ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒë„ íŒë‹¨ì— í™œìš©
    crop_eff = crop_hint or crop_auto
    loc_eff  = location_hint or loc_auto

    # ìµœì¢… ê²Œì´íŠ¸: ì¶©ë¶„íˆ ê´€ë ¨(í‚¤ì›Œë“œ ë§¤ì¹­)í•˜ê±°ë‚˜, ë„ë©”ì¸ìŠ¤ëŸ¬ìš´ êµ¬ì¡° ì‹ í˜¸(ì‘ë¬¼/ìœ„ì¹˜) ì¡´ì¬
    is_related_final = (domain_hits >= min_hits) or bool(crop_eff or loc_eff)

    if not is_related_final:
        return PlainTextResponse(REJECT_MSG)

    # 3) íŒíŠ¸ ë³‘í•©(ì‚¬ìš©ì ì…ë ¥ ìš°ì„  â†’ ì—†ìœ¼ë©´ analyse ê²°ê³¼)
    merged_date = date_hint or res.get("date_hint")
    merged_crop = crop_hint or crop_auto
    merged_loc  = location_hint or loc_auto
    merged_qs   = search_queries or res.get("search_queries") or []

    # 4) íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    global _pipeline
    if _pipeline is None:
        _pipeline = FarmLogPipeline()

    return _pipeline.run(
        stt_text=stt_text,
        date_hint=merged_date,
        crop_hint=merged_crop,
        location_hint=merged_loc,
        search_queries=merged_qs,
    )

# =========================
# Summarise: ììœ  í…ìŠ¤íŠ¸
# =========================
@app.post("/summarise", response_model=FarmLog)
def summarise(req: SummariseRequest):
    return _run_with_analysis(
        stt_text=req.stt_text,
        date_hint=req.date_hint,
        crop_hint=req.crop_hint,
        location_hint=req.location_hint,
        search_queries=req.search_queries,
    )

# =========================
# Summarise: íŒŒì¼ ì„ íƒ
# =========================
@app.post("/summarise_file", response_model=FarmLog)
def summarise_file(req: SummariseFileRequest):
    filename = req.filename
    if not filename:
        items = _list_text_files()
        if not items:
            raise HTTPException(status_code=404, detail="no .txt files under TEXT_DIR")
        filename = sorted(items, key=lambda x: x.mtime, reverse=True)[0].name
    stt_text = _read_text_file_safe(filename)
    return _run_with_analysis(
        stt_text=stt_text,
        date_hint=req.date_hint,
        crop_hint=req.crop_hint,
        location_hint=req.location_hint,
        search_queries=req.search_queries,
    )

# =========================
# Summarise: ê²½ë¡œë§Œ (text/plain)
# =========================
@app.post("/summarise_path", response_model=FarmLog)
def summarise_path(path: str = Body(..., media_type="text/plain")):
    filename = _normalise_to_basename(path)
    stt_text = _read_text_file_safe(filename)
    return _run_with_analysis(stt_text=stt_text)

# =========================
# Summarise: ê²½ë¡œ JSON
# =========================
@app.post("/summarise_path_json", response_model=FarmLog)
def summarise_path_json(req: SummarisePathJSON):
    filename = _normalise_to_basename(req.path)
    stt_text = _read_text_file_safe(filename)
    return _run_with_analysis(
        stt_text=stt_text,
        date_hint=req.date_hint,
        crop_hint=req.crop_hint,
        location_hint=req.location_hint,
        search_queries=req.search_queries,
    )

# =========================
# Summarise: ìë™(ê²½ë¡œ or í…ìŠ¤íŠ¸)
# =========================
@app.post("/summarise_auto", response_model=FarmLog)
def summarise_auto(req: SummariseAutoRequest):
    if not req.path and not req.stt_text:
        raise HTTPException(status_code=400, detail="either path or stt_text is required")
    if req.path:
        filename = _normalise_to_basename(req.path)
        stt_text = _read_text_file_safe(filename)
    else:
        stt_text = (req.stt_text or "").strip()
    # date_hintë§Œ ì‚¬ìš©ì override í—ˆìš©(ë‚˜ë¨¸ì§€ëŠ” analyse ê²°ê³¼ ì‚¬ìš©)
    return _run_with_analysis(
        stt_text=stt_text,
        date_hint=req.date_hint,
        crop_hint=None,
        location_hint=None,
        search_queries=None,
    )

# =========================
# KB ì¬ì¸ë±ì‹±(+í‚¤ì›Œë“œ ì¬ë¡œë”©)
# =========================
@app.post("/ingest")
def ingest(req: IngestRequest):
    kb_dir = req.kb_dir or KB_DIR
    try:
        vs, backend = build_or_load_vectorstore(
            kb_dir=kb_dir, persist_dir=CHROMA_DIR,
            force_vectorstore=os.getenv("FORCE_VECTORSTORE")
        )
        global _pipeline
        _pipeline = None
        app.state.vector_backend = backend
        # í‚¤ì›Œë“œ ì¬ë¡œë”© (ë¹ˆ ê²°ê³¼ë©´ ê¸°ë³¸ í‚¤ì›Œë“œ í´ë°±)
        try:
            kws = _load_farm_keywords(KEYWORDS_PATH)
            if not kws:
                kws = set(_DEFAULT_FARM_KEYWORDS)
            app.state.farm_keywords = kws
        except Exception:
            app.state.farm_keywords = set(_DEFAULT_FARM_KEYWORDS)

        return {
            "status": "ok",
            "kb_dir": kb_dir,
            "vector_backend": backend,
            "keywords_count": len(app.state.farm_keywords)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ingest failed: {e}")
